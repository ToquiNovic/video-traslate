{"text": " Hoy te voy a ense\u00f1ar c\u00f3mo puedes usar Inteligencia Artificial y Python para pasar un v\u00eddeo de YouTube a texto. Lo primero y m\u00e1s importante es que necesitas estas dependencias, whisper, pytube y por supuesto FFMP, importamos las dependencias de pytube y whisper, creamos una variable con nuestro v\u00eddeo de youtube y una variable donde vamos a cargar el modelo de whisper. En este caso vamos a utilizar el small que es bastante r\u00e1pido y funciona bien. Recuperamos el v\u00eddeo de youtube con pytube y lo convertimos en audio. Vamos a descargar este archivo de audio, creamos una variable result donde guardaremos los resultados del modelo una vez que estamos transcribiendo el archivo que hab\u00edamos descargado y finalmente solo tenemos que pintar los resultados, guardamos los cambios y ejecutamos nuestro fichero. Es normal que tarde un poco porque tiene que descargarse el modelo que son unos cuantos megas y adem\u00e1s utilizando machine learning va a entender el audio. Y despu\u00e9s de un rato ya tenemos justamente el texto de nuestro v\u00eddeo transcrito. Si te ha gustado esto dale like.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 4.0, "text": " Hoy te voy a ense\u00f1ar c\u00f3mo puedes usar Inteligencia Artificial y Python para pasar un v\u00eddeo de", "tokens": [50364, 28664, 535, 7552, 257, 31275, 289, 12826, 19010, 14745, 19762, 3213, 2755, 5735, 10371, 288, 15329, 1690, 25344, 517, 8071, 368, 50564], "temperature": 0.0, "avg_logprob": -0.2053254896594632, "compression_ratio": 1.8106508875739644, "no_speech_prob": 0.038566991686820984}, {"id": 1, "seek": 0, "start": 4.0, "end": 5.44, "text": " YouTube a texto.", "tokens": [50564, 3088, 257, 35503, 13, 50636], "temperature": 0.0, "avg_logprob": -0.2053254896594632, "compression_ratio": 1.8106508875739644, "no_speech_prob": 0.038566991686820984}, {"id": 2, "seek": 0, "start": 5.44, "end": 9.200000000000001, "text": " Lo primero y m\u00e1s importante es que necesitas estas dependencias, whisper, pytube y por", "tokens": [50636, 6130, 21289, 288, 3573, 9416, 785, 631, 11909, 14182, 13897, 5672, 37246, 11, 26018, 11, 10664, 83, 1977, 288, 1515, 50824], "temperature": 0.0, "avg_logprob": -0.2053254896594632, "compression_ratio": 1.8106508875739644, "no_speech_prob": 0.038566991686820984}, {"id": 3, "seek": 0, "start": 9.200000000000001, "end": 13.88, "text": " supuesto FFMP, importamos las dependencias de pytube y whisper, creamos una variable", "tokens": [50824, 34177, 479, 37, 12224, 11, 974, 2151, 2439, 5672, 37246, 368, 10664, 83, 1977, 288, 26018, 11, 1197, 2151, 2002, 7006, 51058], "temperature": 0.0, "avg_logprob": -0.2053254896594632, "compression_ratio": 1.8106508875739644, "no_speech_prob": 0.038566991686820984}, {"id": 4, "seek": 0, "start": 13.88, "end": 17.56, "text": " con nuestro v\u00eddeo de youtube y una variable donde vamos a cargar el modelo de whisper.", "tokens": [51058, 416, 14726, 8071, 368, 12487, 288, 2002, 7006, 10488, 5295, 257, 1032, 2976, 806, 27825, 368, 26018, 13, 51242], "temperature": 0.0, "avg_logprob": -0.2053254896594632, "compression_ratio": 1.8106508875739644, "no_speech_prob": 0.038566991686820984}, {"id": 5, "seek": 0, "start": 17.56, "end": 20.88, "text": " En este caso vamos a utilizar el small que es bastante r\u00e1pido y funciona bien.", "tokens": [51242, 2193, 4065, 9666, 5295, 257, 24060, 806, 1359, 631, 785, 14651, 24893, 288, 26210, 3610, 13, 51408], "temperature": 0.0, "avg_logprob": -0.2053254896594632, "compression_ratio": 1.8106508875739644, "no_speech_prob": 0.038566991686820984}, {"id": 6, "seek": 0, "start": 20.88, "end": 24.28, "text": " Recuperamos el v\u00eddeo de youtube con pytube y lo convertimos en audio.", "tokens": [51408, 9647, 12879, 2151, 806, 8071, 368, 12487, 416, 10664, 83, 1977, 288, 450, 7620, 8372, 465, 6278, 13, 51578], "temperature": 0.0, "avg_logprob": -0.2053254896594632, "compression_ratio": 1.8106508875739644, "no_speech_prob": 0.038566991686820984}, {"id": 7, "seek": 0, "start": 24.28, "end": 28.0, "text": " Vamos a descargar este archivo de audio, creamos una variable result donde guardaremos", "tokens": [51578, 10894, 257, 730, 6166, 2976, 4065, 3912, 6340, 368, 6278, 11, 1197, 2151, 2002, 7006, 1874, 10488, 6290, 23118, 51764], "temperature": 0.0, "avg_logprob": -0.2053254896594632, "compression_ratio": 1.8106508875739644, "no_speech_prob": 0.038566991686820984}, {"id": 8, "seek": 2800, "start": 28.0, "end": 32.08, "text": " los resultados del modelo una vez que estamos transcribiendo el archivo que hab\u00edamos descargado", "tokens": [50364, 1750, 36796, 1103, 27825, 2002, 5715, 631, 10382, 1145, 1142, 65, 7304, 806, 3912, 6340, 631, 3025, 16275, 730, 6166, 30135, 50568], "temperature": 0.0, "avg_logprob": -0.1612631742619286, "compression_ratio": 1.6832740213523132, "no_speech_prob": 0.27439799904823303}, {"id": 9, "seek": 2800, "start": 32.08, "end": 36.44, "text": " y finalmente solo tenemos que pintar los resultados, guardamos los cambios y ejecutamos nuestro", "tokens": [50568, 288, 35577, 6944, 9914, 631, 23924, 289, 1750, 36796, 11, 6290, 2151, 1750, 18751, 2717, 288, 39564, 6672, 2151, 14726, 50786], "temperature": 0.0, "avg_logprob": -0.1612631742619286, "compression_ratio": 1.6832740213523132, "no_speech_prob": 0.27439799904823303}, {"id": 10, "seek": 2800, "start": 36.44, "end": 37.44, "text": " fichero.", "tokens": [50786, 283, 480, 2032, 13, 50836], "temperature": 0.0, "avg_logprob": -0.1612631742619286, "compression_ratio": 1.6832740213523132, "no_speech_prob": 0.27439799904823303}, {"id": 11, "seek": 2800, "start": 37.44, "end": 40.32, "text": " Es normal que tarde un poco porque tiene que descargarse el modelo que son unos cuantos", "tokens": [50836, 2313, 2710, 631, 27367, 517, 10639, 4021, 7066, 631, 730, 6166, 2976, 405, 806, 27825, 631, 1872, 17780, 2702, 394, 329, 50980], "temperature": 0.0, "avg_logprob": -0.1612631742619286, "compression_ratio": 1.6832740213523132, "no_speech_prob": 0.27439799904823303}, {"id": 12, "seek": 2800, "start": 40.32, "end": 43.84, "text": " megas y adem\u00e1s utilizando machine learning va a entender el audio.", "tokens": [50980, 10816, 296, 288, 21251, 19906, 1806, 3479, 2539, 2773, 257, 20054, 806, 6278, 13, 51156], "temperature": 0.0, "avg_logprob": -0.1612631742619286, "compression_ratio": 1.6832740213523132, "no_speech_prob": 0.27439799904823303}, {"id": 13, "seek": 2800, "start": 43.84, "end": 48.04, "text": " Y despu\u00e9s de un rato ya tenemos justamente el texto de nuestro v\u00eddeo transcrito.", "tokens": [51156, 398, 15283, 368, 517, 367, 2513, 2478, 9914, 41056, 806, 35503, 368, 14726, 8071, 1145, 10757, 3528, 13, 51366], "temperature": 0.0, "avg_logprob": -0.1612631742619286, "compression_ratio": 1.6832740213523132, "no_speech_prob": 0.27439799904823303}, {"id": 14, "seek": 2800, "start": 48.04, "end": 49.8, "text": " Si te ha gustado esto dale like.", "tokens": [51366, 4909, 535, 324, 45221, 7433, 27326, 411, 13, 51454], "temperature": 0.0, "avg_logprob": -0.1612631742619286, "compression_ratio": 1.6832740213523132, "no_speech_prob": 0.27439799904823303}], "language": "es"}